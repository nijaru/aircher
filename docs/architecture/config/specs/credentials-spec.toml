# Aircher Credential Management Specification

## Overview

This document specifies how Aircher handles API key storage and authentication, providing secure credential management with excellent user experience through the `aircher login` command.

## File Structure

```
~/.config/aircher/
├── config.toml          # User preferences (no secrets)
├── credentials.toml     # API keys (600 permissions)
└── cache/
    └── models.json      # Cached models.dev data
```

### Project-specific (optional):
```
project/.agents/
├── config.toml          # Project overrides
└── credentials.toml     # Project-specific keys (optional)
```

## Credential Storage Format

### `~/.config/aircher/credentials.toml`
```toml
# Aircher API Credentials
# This file is automatically managed by `aircher login`
# File permissions: 600 (user read/write only)

[openai]
api_key = "sk-..."
organization = ""  # optional
project = ""       # optional

[anthropic]
api_key = "sk-ant-..."

[google]
api_key = "AI..."
project_id = ""    # optional for Vertex AI

[groq]
api_key = "gsk_..."

[openrouter]
api_key = "sk-or-..."

[ollama]
base_url = "http://localhost:11434"
# No API key needed for local Ollama

# Custom providers
[custom.my_provider]
api_key = "..."
base_url = "https://api.example.com/v1"
```

## Security Requirements

### File Permissions
- `credentials.toml`: 600 (user read/write only)
- `config.toml`: 644 (normal user file)
- Directory: 755 (normal directory)

### Security Practices
1. **Never log API keys** - redact in logs and error messages
2. **Validate keys on storage** - test API connectivity before saving
3. **Encrypt in memory** - zero out key strings after use
4. **Environment variable fallback** - check env vars if file missing
5. **Clear error messages** - help users fix auth issues

## CLI Authentication Commands

### `aircher login`
Interactive authentication setup with provider selection:
```bash
$ aircher login
? Select a provider to configure:
  > OpenAI (GPT-4, GPT-3.5)
    Anthropic (Claude)
    Google (Gemini)
    Groq (Fast inference)
    OpenRouter (Multiple models)
    Ollama (Local models)
    Custom provider

? Paste your OpenAI API key: [input hidden]
✓ Testing connection...
✓ API key validated successfully
✓ Available models: gpt-4, gpt-4-turbo, gpt-3.5-turbo
? Set as default provider? (Y/n) y
✓ Configuration saved to ~/.config/aircher/credentials.toml
```

### `aircher login <provider>`
Direct provider configuration:
```bash
$ aircher login openai
? Paste your OpenAI API key: [input hidden]
✓ Testing connection...
✓ Configuration saved

$ aircher login anthropic
? Paste your Anthropic API key: [input hidden]
✓ Testing connection...
✓ Configuration saved
```

### `aircher login --check`
Validate existing credentials:
```bash
$ aircher login --check
✓ OpenAI: Connected (gpt-4, gpt-4-turbo available)
✗ Anthropic: Invalid API key
- Google: Not configured
✓ Ollama: Connected (llama2, codellama available)
```

### `aircher logout <provider>`
Remove credentials:
```bash
$ aircher logout openai
? Remove OpenAI credentials? (y/N) y
✓ OpenAI credentials removed
```

## Configuration File (No Secrets)

### `~/.config/aircher/config.toml`
```toml
# Aircher Configuration
# User preferences and non-sensitive settings

[providers]
default = "openai"           # Which provider to use by default
fallback_enabled = true     # Auto-fallback to other providers
fallback_order = ["openai", "anthropic", "google"]

[models]
# Model preferences (provider-specific defaults)
openai_default = "gpt-4"              # Latest GPT-4 variant
anthropic_default = "claude-3-5-sonnet"  # Latest Sonnet
google_default = "gemini-2.5-pro"        # Latest Gemini Pro
auto_select = true                    # Smart model selection based on task

[interface]
show_thinking = true
show_context_usage = true     # Show "44k/200k tokens"
show_cost = true             # Show cost estimates
markdown_rendering = true
streaming = true
vim_mode = false             # Future feature

[context]
max_files = 20               # Max files in context
relevance_threshold = 0.3    # File relevance cutoff
auto_compaction = true       # Smart context management

[costs]
monthly_budget = 100.0       # USD budget limit
warn_threshold = 0.8         # Warn at 80% of budget
track_usage = true           # Track and display costs
```

## Provider Detection Logic

### Environment Variable Fallback
```go
func GetAPIKey(provider string) (string, error) {
    // 1. Check project credentials
    if key := getProjectCredential(provider); key != "" {
        return key, nil
    }

    // 2. Check user credentials file
    if key := getUserCredential(provider); key != "" {
        return key, nil
    }

    // 3. Fall back to environment variables
    envKey := getEnvVarName(provider)
    if key := os.Getenv(envKey); key != "" {
        return key, nil
    }

    return "", fmt.Errorf("no API key found for %s", provider)
}
```

### Auto Provider Detection
```go
func DetectAvailableProviders() []string {
    var available []string

    providers := []string{"openai", "anthropic", "google", "groq", "openrouter"}

    for _, provider := range providers {
        if _, err := GetAPIKey(provider); err == nil {
            available = append(available, provider)
        }
    }

    // Always include Ollama if running
    if isOllamaRunning() {
        available = append(available, "ollama")
    }

    return available
}
```

## Default Model Selection

### Hardcoded Smart Defaults
```go
var DefaultModels = map[string]string{
    "openai":     "gpt-4",                    // Their flagship model
    "anthropic":  "claude-3-5-sonnet-latest", // Latest Sonnet
    "google":     "gemini-2.5-pro",           // Latest Pro
    "groq":       "llama-3.1-70b-versatile", // Good balance
    // openrouter and ollama have no defaults - require user selection
}
```

### Model Selection Logic
```go
func SelectModel(provider string, userPreference string) string {
    // 1. User explicitly set model
    if userPreference != "" {
        return userPreference
    }

    // 2. Check config file default
    if configDefault := getConfigDefault(provider); configDefault != "" {
        return configDefault
    }

    // 3. Use hardcoded smart default
    if defaultModel, exists := DefaultModels[provider]; exists {
        return defaultModel
    }

    // 4. For providers without defaults, prompt user
    return promptUserForModel(provider)
}
```

## Models.dev Integration

### Caching Strategy
```go
type ModelCache struct {
    Data       map[string]interface{} `json:"data"`
    LastUpdate time.Time              `json:"last_update"`
    TTL        time.Duration          `json:"ttl"`
}

func UpdateModelCache() error {
    // Fetch from models.dev API
    // Cache for 24 hours
    // Use cached data if API unavailable
}
```

### Model Information Usage
- **Context Limits**: Get from models.dev for accurate limits
- **Pricing**: Real-time cost calculation
- **Capabilities**: Feature detection (vision, tools, etc.)
- **Fallback**: Hardcoded minimums if API unavailable

## Error Handling

### Invalid API Keys
```
✗ Error: OpenAI API key is invalid

  To fix this:
  1. Get a new API key from https://platform.openai.com/api-keys
  2. Run: aircher login openai
  3. Paste your new key when prompted
```

### Missing Credentials
```
✗ Error: No API key configured for OpenAI

  To get started:
  1. Run: aircher login openai
  2. Get an API key from https://platform.openai.com/api-keys
  3. Paste it when prompted
```

### Network Issues
```
⚠ Warning: Cannot connect to OpenAI (network issue)
  Falling back to Anthropic Claude...
```

## Implementation Priority

### Phase 1 (MVP)
1. `aircher login` interactive setup
2. Credential file management with proper permissions
3. Basic provider detection (OpenAI, Anthropic)
4. Environment variable fallback
5. Hardcoded smart defaults

### Phase 2 (Enhanced)
1. models.dev API integration
2. More providers (Google, Groq, OpenRouter)
3. Credential validation and health checks
4. Advanced fallback logic
5. Cost tracking integration

### Phase 3 (Advanced)
1. Project-specific credentials
2. Team credential sharing (encrypted)
3. Credential rotation and management
4. Advanced security features
5. Enterprise integrations

## File Permissions Implementation

### Go Implementation
```go
func SaveCredentials(creds *Credentials) error {
    credPath := getCredentialsPath()

    // Ensure directory exists with proper permissions
    if err := os.MkdirAll(filepath.Dir(credPath), 0755); err != nil {
        return err
    }

    // Write file with restricted permissions
    data, err := toml.Marshal(creds)
    if err != nil {
        return err
    }

    return os.WriteFile(credPath, data, 0600) // User read/write only
}
```

This approach provides:
- **Excellent UX**: Simple `aircher login` command
- **Security**: Proper file permissions and no secrets in config
- **Flexibility**: Environment variable fallback
- **Smart defaults**: Works out of the box with minimal configuration
- **Clear errors**: Helpful messages for common issues
